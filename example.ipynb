{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./semantic-object-accuracy-for-generative-text-to-image-synthesis/SOA/captions/label_00_person.pkl', 'rb') as f:\n",
    "    j=pk.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'idx': [1, 0], 'image_id': 412975, 'id': 225289, 'caption': 'A woman walking across a street in short shorts.'}\n"
     ]
    }
   ],
   "source": [
    "print(j[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPGAN get 50 images as example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training on GPU ./semantic-object-accuracy-for-generative-text-to-image-synthesis/OP-GAN/sample.sh.\n",
      "dirop output/coco_attn2_2021_05_14_14_47_09_3\n",
      "14-05-2021 14:47:09 - INFO - Using output dir: output/coco_attn2_2021_05_14_14_47_09_3\n",
      "14-05-2021 14:47:09 - INFO - Using seed 3\n",
      "14-05-2021 14:47:09 - INFO - USING DEVICE cpu\n",
      "14-05-2021 14:47:09 - INFO - Using config: \n",
      "{'CONFIG_NAME': 'attn2',\n",
      " 'CUDA': False,\n",
      " 'DATASET_NAME': 'coco',\n",
      " 'DATA_DIR': './semantic-object-accuracy-for-generative-text-to-image-synthesis/OP-GAN/data',\n",
      " 'DEBUG': False,\n",
      " 'DEBUG_NUM_DATAPOINTS': 100,\n",
      " 'DEVICE': device(type='cpu'),\n",
      " 'GAN': {'B_ATTENTION': True,\n",
      "         'B_DCGAN': False,\n",
      "         'DISC_FEAT_DIM': 96,\n",
      "         'GEN_FEAT_DIM': 48,\n",
      "         'GLOBAL_Z_DIM': 100,\n",
      "         'INIT_LABEL_DIM': 100,\n",
      "         'LAYOUT_SPATIAL_DIM': 16,\n",
      "         'LOCAL_Z_DIM': 32,\n",
      "         'NEXT_LABEL_DIM': 128,\n",
      "         'RESIDUAL_NUM': 3,\n",
      "         'TEXT_CONDITION_DIM': 100},\n",
      " 'OUTPUT_DIR': 'output',\n",
      " 'RNN_TYPE': 'LSTM',\n",
      " 'SEED': 3,\n",
      " 'TEXT': {'CAPTIONS_PER_IMAGE': 5,\n",
      "          'CLASSES_NUM': 81,\n",
      "          'EMBEDDING_DIM': 256,\n",
      "          'WORDS_NUM': 20},\n",
      " 'TRAIN': {'BATCH_SIZE': [50],\n",
      "           'BBOX_LOSS': True,\n",
      "           'B_NET_D': False,\n",
      "           'DISCRIMINATOR_LR': 0.0002,\n",
      "           'EMPTY_CACHE': False,\n",
      "           'ENCODER_LR': 0.0002,\n",
      "           'FLAG': False,\n",
      "           'GENERATED_BBOXES': True,\n",
      "           'GENERATOR_LR': 0.0002,\n",
      "           'MAX_EPOCH': 120,\n",
      "           'NET_E': './semantic-object-accuracy-for-generative-text-to-image-synthesis/OP-GAN/models/coco/text_encoder100.pth',\n",
      "           'NET_G': './semantic-object-accuracy-for-generative-text-to-image-synthesis/OP-GAN/models/op-gan.pth',\n",
      "           'OPTIMIZE_DATA_LOADING': False,\n",
      "           'RNN_GRAD_CLIP': 0.25,\n",
      "           'SMOOTH': {'GAMMA1': 5.0,\n",
      "                      'GAMMA2': 5.0,\n",
      "                      'GAMMA3': 10.0,\n",
      "                      'LAMBDA': 1.0}},\n",
      " 'TREE': {'BASE_SIZE': 64, 'BRANCH_NUM': 3},\n",
      " 'WORKERS': 1}\n",
      "14-05-2021 14:47:09 - INFO - Load bounding boxes: (40470, 5, 10, 4)\n",
      "14-05-2021 14:47:09 - INFO - Load Labels: (40470, 5, 10)\n",
      "14-05-2021 14:47:09 - INFO - Load filenames from: ./semantic-object-accuracy-for-generative-text-to-image-synthesis/OP-GAN/data/train/filenames.pickle (82783)\n",
      "14-05-2021 14:47:09 - INFO - Load filenames from: ./semantic-object-accuracy-for-generative-text-to-image-synthesis/OP-GAN/data/test/filenames.pickle (40470)\n",
      "14-05-2021 14:47:10 - INFO - Load captions from: ./semantic-object-accuracy-for-generative-text-to-image-synthesis/OP-GAN/data/captions.pickle\n",
      "14-05-2021 14:47:10 - INFO - Captions: 202350\n",
      "/home/jp5881/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "14-05-2021 14:47:11 - INFO - Loaded text encoder from: ./semantic-object-accuracy-for-generative-text-to-image-synthesis/OP-GAN/models/coco/text_encoder100.pth\n",
      "14-05-2021 14:47:11 - INFO - Load G from: ./semantic-object-accuracy-for-generative-text-to-image-synthesis/OP-GAN/models/op-gan.pth\n",
      "14-05-2021 14:47:11 - INFO - Saving images to: ./semantic-object-accuracy-for-generative-text-to-image-synthesis/OP-GAN//output/op-gan/valid\n",
      "100%|█████████████████████████████████████████████| 2/2 [02:48<00:00, 84.10s/it]\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "!sh ./opgan/OP-GAN/sample.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPGAN get 50 images as example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training on the MS-COCO data set.\n",
      "Going to MS-COCO folder.\n",
      "/scratch/jp5881/multiple-objects-gan/code/coco/attngan/miscc/config.py:104: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  yaml_cfg = edict(yaml.load(f))\n",
      "Using config:\n",
      "{'B_VALIDATION': True,\n",
      " 'CONFIG_NAME': 'attn2',\n",
      " 'CUDA': True,\n",
      " 'DATASET_NAME': 'coco',\n",
      " 'DATA_DIR': '/scratch/jp5881/multiple-objects-gan/data/MS-COCO/coco/coco',\n",
      " 'GAN': {'B_ATTENTION': True,\n",
      "         'B_DCGAN': False,\n",
      "         'CONDITION_DIM': 100,\n",
      "         'DF_DIM': 96,\n",
      "         'GF_DIM': 48,\n",
      "         'R_NUM': 3,\n",
      "         'Z_DIM': 100},\n",
      " 'GPU_ID': '0',\n",
      " 'IMG_DIR': '/scratch/jp5881/multiple-objects-gan/data/MS-COCO/test/val2014',\n",
      " 'RNN_TYPE': 'LSTM',\n",
      " 'TEXT': {'CAPTIONS_PER_IMAGE': 5, 'EMBEDDING_DIM': 256, 'WORDS_NUM': 20},\n",
      " 'TRAIN': {'BATCH_SIZE': 50,\n",
      "           'B_NET_D': False,\n",
      "           'DISCRIMINATOR_LR': 0.0002,\n",
      "           'ENCODER_LR': 0.0002,\n",
      "           'FLAG': False,\n",
      "           'GENERATOR_LR': 0.0002,\n",
      "           'MAX_EPOCH': 600,\n",
      "           'NET_E': '/scratch/jp5881/multiple-objects-gan/code/coco/attngan/DAMSMencoders/text_encoder100.pth',\n",
      "           'NET_G': '/scratch/jp5881/multiple-objects-gan/models/model-ms-coco-attngan/model-ms-coco-attngan-0100.pth',\n",
      "           'RNN_GRAD_CLIP': 0.25,\n",
      "           'SMOOTH': {'GAMMA1': 5.0,\n",
      "                      'GAMMA2': 5.0,\n",
      "                      'GAMMA3': 10.0,\n",
      "                      'LAMBDA': 1.0},\n",
      "           'SNAPSHOT_INTERVAL': 2000},\n",
      " 'TREE': {'BASE_SIZE': 64, 'BRANCH_NUM': 3},\n",
      " 'WORKERS': 1}\n",
      "bboxes:  (40470, 3, 4)\n",
      "labels:  (40470, 3, 1)\n",
      "Load filenames from: /scratch/jp5881/multiple-objects-gan/data/MS-COCO/coco/coco/train/filenames.pickle (82783)\n",
      "Load filenames from: /scratch/jp5881/multiple-objects-gan/data/MS-COCO/coco/coco/test/filenames.pickle (40470)\n",
      "Load from:  /scratch/jp5881/multiple-objects-gan/data/MS-COCO/coco/coco/captions.pickle\n",
      "/home/jp5881/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "Load text encoder from: /scratch/jp5881/multiple-objects-gan/code/coco/attngan/DAMSMencoders/text_encoder100.pth\n",
      "Load G from:  /scratch/jp5881/multiple-objects-gan/models/model-ms-coco-attngan/model-ms-coco-attngan-0100.pth\n",
      "/home/jp5881/.local/lib/python3.8/site-packages/torch/nn/functional.py:3890: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "/home/jp5881/.local/lib/python3.8/site-packages/torch/nn/functional.py:3828: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "Saved 10 files to /scratch/jp5881/multiple-objects-gan/models/model-ms-coco-attngan/model-ms-coco-attngan-0100_valid\n"
     ]
    }
   ],
   "source": [
    "!sh ./text2img/sample.sh coco-attngan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STACKGAN get 50 images as example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training on the MS-COCO data set.\n",
      "Going to MS-COCO folder.\n",
      "/scratch/jp5881/multiple-objects-gan/code/coco/stackgan/miscc/config.py:97: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  yaml_cfg = edict(yaml.load(f))\n",
      "Using config:\n",
      "{'CONFIG_NAME': 'stageI',\n",
      " 'CUDA': True,\n",
      " 'DATASET_NAME': 'coco',\n",
      " 'DATA_DIR': '/scratch/jp5881/multiple-objects-gan/data/MS-COCO/coco/coco',\n",
      " 'EMBEDDING_TYPE': 'cnn-rnn',\n",
      " 'GAN': {'CONDITION_DIM': 128, 'DF_DIM': 96, 'GF_DIM': 192, 'R_NUM': 2},\n",
      " 'GPU_ID': '0',\n",
      " 'IMG_DIR': '/scratch/jp5881/multiple-objects-gan/data/MS-COCO/test/val2014',\n",
      " 'IMSIZE': 256,\n",
      " 'NET_D': '',\n",
      " 'NET_G': '/scratch/jp5881/multiple-objects-gan/models/model-coco-stackgan-stage-ii-0110.pth',\n",
      " 'STAGE': 2,\n",
      " 'STAGE1_G': '',\n",
      " 'TEXT': {'DIMENSION': 1024},\n",
      " 'TRAIN': {'BATCH_SIZE': 100,\n",
      "           'COEFF': {'KL': 2.0},\n",
      "           'DISCRIMINATOR_LR': 0.0002,\n",
      "           'FLAG': False,\n",
      "           'GENERATOR_LR': 0.0002,\n",
      "           'LR_DECAY_EPOCH': 600,\n",
      "           'MAX_EPOCH': 600,\n",
      "           'PRETRAINED_EPOCH': 600,\n",
      "           'PRETRAINED_MODEL': '',\n",
      "           'SNAPSHOT_INTERVAL': 50},\n",
      " 'USE_BBOX_LAYOUT': True,\n",
      " 'USE_LOCAL_PATHWAY': True,\n",
      " 'VIS_COUNT': 64,\n",
      " 'WORKERS': 4,\n",
      " 'Z_DIM': 100}\n",
      "STAGE2_G(\n",
      "  (STAGE1_G): STAGE1_G(\n",
      "    (ca_net): CA_NET(\n",
      "      (fc): Linear(in_features=1024, out_features=256, bias=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (bbox_net): BBOX_NET(\n",
      "      (encode): Sequential(\n",
      "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        (2): Conv2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "        (5): Conv2d(32, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (6): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=292, out_features=24576, bias=False)\n",
      "      (1): BatchNorm1d(24576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (label): Sequential(\n",
      "      (0): Linear(in_features=209, out_features=128, bias=False)\n",
      "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (local1): Sequential(\n",
      "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
      "      (1): Conv2d(128, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "    )\n",
      "    (local2): Sequential(\n",
      "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
      "      (1): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "    )\n",
      "    (upsample1): Sequential(\n",
      "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
      "      (1): Conv2d(1536, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "    )\n",
      "    (upsample2): Sequential(\n",
      "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
      "      (1): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "    )\n",
      "    (upsample3): Sequential(\n",
      "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
      "      (1): Conv2d(768, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "    )\n",
      "    (upsample4): Sequential(\n",
      "      (0): Upsample(scale_factor=2.0, mode=nearest)\n",
      "      (1): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "    )\n",
      "    (img): Sequential(\n",
      "      (0): Conv2d(96, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (ca_net): CA_NET(\n",
      "    (fc): Linear(in_features=1024, out_features=256, bias=True)\n",
      "    (relu): ReLU()\n",
      "  )\n",
      "  (label): Sequential(\n",
      "    (0): Linear(in_features=209, out_features=128, bias=False)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (local1): Sequential(\n",
      "    (0): Upsample(scale_factor=2.0, mode=nearest)\n",
      "    (1): Conv2d(896, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (local2): Sequential(\n",
      "    (0): Upsample(scale_factor=2.0, mode=nearest)\n",
      "    (1): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv2d(3, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(192, 384, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Conv2d(384, 768, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): ReLU(inplace=True)\n",
      "  )\n",
      "  (hr_joint): Sequential(\n",
      "    (0): Conv2d(1024, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (residual): Sequential(\n",
      "    (0): ResBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): ResBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (upsample1): Sequential(\n",
      "    (0): Upsample(scale_factor=2.0, mode=nearest)\n",
      "    (1): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (upsample2): Sequential(\n",
      "    (0): Upsample(scale_factor=2.0, mode=nearest)\n",
      "    (1): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (upsample3): Sequential(\n",
      "    (0): Upsample(scale_factor=2.0, mode=nearest)\n",
      "    (1): Conv2d(384, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (upsample4): Sequential(\n",
      "    (0): Upsample(scale_factor=2.0, mode=nearest)\n",
      "    (1): Conv2d(96, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (img): Sequential(\n",
      "    (0): Conv2d(48, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): Tanh()\n",
      "  )\n",
      ")\n",
      "Load from:  /scratch/jp5881/multiple-objects-gan/models/model-coco-stackgan-stage-ii-0110.pth\n",
      "STAGE2_D(\n",
      "  (local): Sequential(\n",
      "    (0): Conv2d(84, 192, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (3): Conv2d(192, 192, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  )\n",
      "  (act): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "  (conv1): Conv2d(3, 96, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (conv2): Conv2d(96, 192, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(192, 384, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv4): Conv2d(576, 768, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn4): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv5): Conv2d(768, 1536, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn5): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv6): Conv2d(1536, 3072, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn6): BatchNorm2d(3072, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv7): Conv2d(3072, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn7): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv8): Conv2d(1536, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn8): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (get_cond_logits): D_GET_LOGITS(\n",
      "    (outlogits): Sequential(\n",
      "      (0): Conv2d(896, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "      (3): Conv2d(768, 1, kernel_size=(4, 4), stride=(4, 4))\n",
      "    )\n",
      "  )\n",
      "  (get_uncond_logits): D_GET_LOGITS(\n",
      "    (outlogits): Sequential(\n",
      "      (0): Conv2d(768, 1, kernel_size=(4, 4), stride=(4, 4))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Successfully load sentences from:  /scratch/jp5881/multiple-objects-gan/data/MS-COCO/coco/coco/test/\n",
      "Total number of sentences: 40470\n",
      "saving to: /scratch/jp5881/multiple-objects-gan/models/model-coco-stackgan-stage-ii-0110_visualize_bbox\n",
      "/home/jp5881/.local/lib/python3.8/site-packages/torch/nn/functional.py:3890: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "/home/jp5881/.local/lib/python3.8/site-packages/torch/nn/functional.py:3828: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "Saved 50 files to /scratch/jp5881/multiple-objects-gan/models/model-coco-stackgan-stage-ii-0110_visualize_bbox\n"
     ]
    }
   ],
   "source": [
    "!sh /scratch/jp5881/text2img/sample.sh coco-stackgan-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate SOA for any GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python calculate_soa.py --images ./text2img/data/coco/test/val2014 --output ./text2img/output "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
